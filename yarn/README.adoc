== Spark on YARN

You can submit Spark applications to a Hadoop YARN cluster using `yarn` <<masterURL, master URL>>.

```
spark-submit --master yarn mySparkApp.jar
```

NOTE: Since Spark *2.0.0*, `yarn` master URL is the only proper master URL and you can use `--deploy-mode` to choose between `client` (default) or `cluster` modes.

.Submitting Spark Application to YARN Cluster (aka Creating SparkContext with yarn Master URL and client Deploy Mode)
image::../images/spark-yarn-ApplicationMaster-client-submitApplication.png[align="center"]

Without specifying the link:spark-deploy-mode.adoc[deploy mode], it is assumed `client`.

```
spark-submit --master yarn --deploy-mode client mySparkApp.jar
```

There are two deploy modes for YARN -- link:spark-yarn-client-yarnclientschedulerbackend.adoc[client] (default) or link:spark-yarn-cluster-yarnclusterschedulerbackend.adoc[cluster].

TIP: Deploy modes are all about where the link:spark-driver.adoc[Spark driver] runs.

In client mode the Spark driver (and link:spark-sparkcontext.adoc[SparkContext]) runs on a client node outside a YARN cluster whereas in cluster mode it runs inside a YARN cluster, i.e. inside a YARN container alongside link:spark-yarn-applicationmaster.adoc[ApplicationMaster] (that acts as the Spark application in YARN).

```
spark-submit --master yarn --deploy-mode cluster mySparkApp.jar
```

In that sense, a Spark application deployed to YARN is a YARN-compatible execution framework that can be deployed to a YARN cluster (alongside other Hadoop workloads). On YARN, a Spark executor maps to a single YARN container.

NOTE: In order to deploy applications to YARN clusters, you need to <<yarn-support, use Spark with YARN support>>.

Spark on YARN supports <<multiple-application-attempts, multiple application attempts>> and supports link:spark-data-locality.adoc[data locality for data in HDFS]. You can also take advantage of Hadoop's security and run Spark in a link:spark-yarn-kerberos.adoc[secure Hadoop environment using Kerberos authentication] (aka _Kerberized clusters_).

There are few settings that are specific to YARN (see <<settings, Settings>>). Among them, you can particularly like the link:spark-submit.adoc#queue[support for YARN resource queues] (to divide cluster resources and allocate shares to different teams and users based on advanced policies).

TIP: You can start link:spark-submit.adoc[spark-submit] with `--verbose` command-line option to have some settings displayed, including YARN-specific. See <<spark-submit, spark-submit and YARN options>>.

The memory in the YARN resource requests is `--executor-memory` + what's set for link:spark-yarn-settings.adoc#spark.yarn.executor.memoryOverhead[spark.yarn.executor.memoryOverhead], which defaults to 10% of `--executor-memory`.

If YARN has enough resources it will deploy the executors distributed across the cluster, then each of them will try to process the data locally (`NODE_LOCAL` in Spark Web UI), with as many splits in parallel as you defined in link:../spark-Executor.adoc#spark.executor.cores[spark.executor.cores].

=== [[multiple-application-attempts]] Multiple Application Attempts

Spark on YARN supports *multiple application attempts* in link:spark-yarn-cluster-yarnclusterschedulerbackend.adoc[cluster mode].

See link:spark-yarn-yarnrmclient.adoc#getMaxRegAttempts[YarnRMClient.getMaxRegAttempts].

CAUTION: FIXME

=== [[spark-submit]] spark-submit and YARN options

When you submit your Spark applications using link:spark-submit.adoc[spark-submit] you can use the following YARN-specific command-line options:

* `--archives`
* `--executor-cores`
* `--keytab`
* `--num-executors`
* `--principal`
* link:spark-submit.adoc#queue[--queue]

TIP: Read about the corresponding settings in <<settings, Settings>> in this document.

=== [[memory]] Memory Requirements

When link:spark-yarn-client.adoc#submitApplication[`Client` submits a Spark application to a YARN cluster], it link:spark-yarn-client.adoc#verifyClusterResources[makes sure that the application will not request more than the maximum memory capability of the YARN cluster].

The memory for `ApplicationMaster` is controlled by custom settings per link:spark-deploy-mode.adoc[deploy mode].

For link:spark-deploy-mode.adoc#client[client deploy mode] it is a sum of link:spark-yarn-settings.adoc#spark.yarn.am.memory[spark.yarn.am.memory] (default: `512m`) with an optional overhead as link:spark-yarn-settings.adoc#spark.yarn.am.memoryOverhead[spark.yarn.am.memoryOverhead].

For link:spark-deploy-mode.adoc#cluster[cluster deploy mode] it is a sum of link:spark-driver.adoc#spark_driver_memory[spark.driver.memory] (default: `1g`) with an optional overhead as link:spark-yarn-settings.adoc#spark.yarn.driver.memoryOverhead[spark.yarn.driver.memoryOverhead].

If the optional overhead is not set, it is computed as link:spark-yarn-YarnSparkHadoopUtil.adoc#MEMORY_OVERHEAD_FACTOR[10%] of the main memory (link:spark-yarn-settings.adoc#spark.yarn.am.memory[spark.yarn.am.memory] for client mode or link:spark-driver.adoc#spark_driver_memory[spark.driver.memory] for cluster mode) or link:spark-yarn-YarnSparkHadoopUtil.adoc##MEMORY_OVERHEAD_MIN[384m] whatever is larger.

=== [[yarn-support]] Spark with YARN support

You need to have Spark that link:../varia/spark-building-from-sources.adoc[has been compiled with YARN support], i.e. the class link:spark-yarn-client.adoc[org.apache.spark.deploy.yarn.Client] must be on the CLASSPATH.

Otherwise, you will see the following error in the logs and Spark will exit.

```
Error: Could not load YARN classes. This copy of Spark may not have been compiled with YARN support.
```

=== [[masterURL]] Master URL

Since Spark *2.0.0*, the only proper master URL is `yarn`.

```
./bin/spark-submit --master yarn ...
```

Before Spark 2.0.0, you could have used `yarn-client` or `yarn-cluster`, but it is now deprecated. When you use the deprecated master URLs, you should see the following warning in the logs:

```
Warning: Master yarn-client is deprecated since 2.0. Please use master "yarn" with specified deploy mode instead.
```

=== [[keytab]] Keytab

CAUTION: FIXME

When a principal is specified a keytab must be specified, too.

The settings link:spark-yarn-settings.adoc#spark.yarn.principal[spark.yarn.principal] and `spark.yarn.principal` will be set to respective values and `UserGroupInformation.loginUserFromKeytab` will be called with their values as input arguments.

=== [[environment-variables]] Environment Variables

==== [[SPARK_DIST_CLASSPATH]] SPARK_DIST_CLASSPATH

`SPARK_DIST_CLASSPATH` is a distribution-defined CLASSPATH to add to processes.

It is used to link:spark-yarn-client.adoc#populateClasspath[populate CLASSPATH for ApplicationMaster and executors].

=== [[settings]] Settings

CAUTION: FIXME Where and how are they used?

=== [[i-want-more]] Further reading or watching

* (video) https://youtu.be/N6pJhxCPe-Y[Spark on YARN: a Deep Dive -- Sandy Ryza (Cloudera)]
* (video) https://youtu.be/sritCTJWQes[Spark on YARN: The Road Ahead -- Marcelo Vanzin (Cloudera)] from Spark Summit 2015
