== [[Aggregate]] Aggregate Unary Logical Operator

`Aggregate` is a link:spark-sql-LogicalPlan.adoc#UnaryNode[unary logical operator] that holds the following:

* [[groupingExpressions]] Grouping link:spark-sql-Expression.adoc[expressions]
* [[aggregateExpressions]] Aggregate link:spark-sql-Expression.adoc#NamedExpression[named expressions]
* [[child]] Child link:spark-sql-LogicalPlan.adoc[logical plan]

`Aggregate` is created to represent the following after a logical plan is link:spark-sql-LogicalPlan.adoc#analyzed[analyzed]:

* SQL's link:spark-sql-AstBuilder.adoc#withAggregation[GROUP BY] clause (possibly with `WITH CUBE` or `WITH ROLLUP`) in `AstBuilder`

* link:spark-sql-RelationalGroupedDataset.adoc[RelationalGroupedDataset] aggregations (e.g. link:spark-sql-RelationalGroupedDataset.adoc#pivot[pivot])

* link:spark-sql-KeyValueGroupedDataset.adoc[KeyValueGroupedDataset] aggregations

* `AnalyzeColumnCommand`

NOTE: `Aggregate` logical operator is translated to one of link:spark-sql-SparkPlan-HashAggregateExec.adoc[HashAggregateExec], link:spark-sql-SparkPlan-ObjectHashAggregateExec.adoc[ObjectHashAggregateExec] or link:spark-sql-SparkPlan-SortAggregateExec.adoc[SortAggregateExec] physical operators in link:spark-sql-SparkStrategy-Aggregation.adoc[Aggregation] execution planning strategy.

[[properties]]
.Aggregate's Properties (in alphabetical order)
[width="100%",cols="1,2",options="header"]
|===
| Name
| Description

| `maxRows`
a| <<child, Child logical plan>>'s `maxRows`

NOTE: Part of link:spark-sql-LogicalPlan.adoc#maxRows[LogicalPlan contract].

| `output`
a| Attributes of <<aggregateExpressions, aggregate named expressions>>

NOTE: Part of link:spark-sql-catalyst-QueryPlan.adoc#output[QueryPlan contract].

| `resolved`
a| Enabled when:

* <<expressions, expressions>> and <<child, child logical plan>> are resolved
* No link:spark-sql-Expression-WindowExpression.adoc[WindowExpressions] exist in <<aggregateExpressions, aggregate named expressions>>

NOTE: Part of link:spark-sql-LogicalPlan.adoc#resolved[LogicalPlan contract].

| `validConstraints`
a| The (expression) constraints of <<child, child logical plan>> and non-aggregate <<aggregateExpressions, aggregate named expressions>>.

NOTE: Part of link:spark-sql-catalyst-QueryPlan.adoc#validConstraints[QueryPlan contract].
|===

=== [[computeStats]] `computeStats` Method

CAUTION: FIXME

NOTE: `computeStats` is a part of link:spark-sql-LogicalPlan.adoc#computeStats[LogicalPlan Contract] to calculating statistics estimates (for cost-based optimizer).

=== [[optimizer]] Rule-Based Logical Optimization Phase

link:spark-sql-Optimizer-PushDownPredicate.adoc[PushDownPredicate] logical plan optimization applies so-called *filter pushdown* to a link:spark-sql-LogicalPlan-Pivot.adoc[Pivot] operator when under `Filter` operator and with all expressions deterministic.

[source, scala]
----
import org.apache.spark.sql.catalyst.optimizer.PushDownPredicate

val q = visits
  .groupBy("city")
  .pivot("year")
  .count()
  .where($"city" === "Boston")

val pivotPlanAnalyzed = q.queryExecution.analyzed
scala> println(pivotPlanAnalyzed.numberedTreeString)
00 Filter (city#8 = Boston)
01 +- Project [city#8, __pivot_count(1) AS `count` AS `count(1) AS ``count```#142[0] AS 2015#143L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#142[1] AS 2016#144L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#142[2] AS 2017#145L]
02    +- Aggregate [city#8], [city#8, pivotfirst(year#9, count(1) AS `count`#134L, 2015, 2016, 2017, 0, 0) AS __pivot_count(1) AS `count` AS `count(1) AS ``count```#142]
03       +- Aggregate [city#8, year#9], [city#8, year#9, count(1) AS count(1) AS `count`#134L]
04          +- Project [_1#3 AS id#7, _2#4 AS city#8, _3#5 AS year#9]
05             +- LocalRelation [_1#3, _2#4, _3#5]

val afterPushDown = PushDownPredicate(pivotPlanAnalyzed)
scala> println(afterPushDown.numberedTreeString)
00 Project [city#8, __pivot_count(1) AS `count` AS `count(1) AS ``count```#142[0] AS 2015#143L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#142[1] AS 2016#144L, __pivot_count(1) AS `count` AS `count(1) AS ``count```#142[2] AS 2017#145L]
01 +- Aggregate [city#8], [city#8, pivotfirst(year#9, count(1) AS `count`#134L, 2015, 2016, 2017, 0, 0) AS __pivot_count(1) AS `count` AS `count(1) AS ``count```#142]
02    +- Aggregate [city#8, year#9], [city#8, year#9, count(1) AS count(1) AS `count`#134L]
03       +- Project [_1#3 AS id#7, _2#4 AS city#8, _3#5 AS year#9]
04          +- Filter (_2#4 = Boston)
05             +- LocalRelation [_1#3, _2#4, _3#5]
----
