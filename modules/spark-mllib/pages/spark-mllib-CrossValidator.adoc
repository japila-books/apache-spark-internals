== [[CrossValidator]] CrossValidator -- Model Tuning / Finding The Best Model

`CrossValidator` is an link:spark-mllib-estimators.md[Estimator] for *model tuning*, i.e. <<fit, finding the best model>> for given <<parameters, parameters>> and a dataset.

`CrossValidator` <<fit-computing-metrics, splits the dataset>> into a set of non-overlapping randomly-partitioned <<numFolds, numFolds>> pairs of training and validation datasets.

`CrossValidator` <<fit, generates>> a `CrossValidatorModel` to hold the best model and average cross-validation metrics.

NOTE: `CrossValidator` takes any <<estimator, Estimator>> for model selection, including the link:spark-mllib-Pipeline.md[Pipeline] that is used to transform raw datasets and generate a link:spark-mllib-Model.md[Model].

NOTE: Use link:spark-mllib-ParamGridBuilder.md[ParamGridBuilder] for the parameter grid, i.e. collection of `ParamMaps` for model tuning.

[source, scala]
----
import org.apache.spark.ml.Pipeline
val pipeline: Pipeline = ...

import org.apache.spark.ml.param.ParamMap
val paramGrid: Array[ParamMap] = new ParamGridBuilder().
  addGrid(...).
  addGrid(...).
  build

import org.apache.spark.ml.tuning.CrossValidator
val cv = new CrossValidator().
  setEstimator(pipeline).
  setEvaluator(...).
  setEstimatorParamMaps(paramGrid).
  setNumFolds(...).
  setParallelism(...)

import org.apache.spark.ml.tuning.CrossValidatorModel
val bestModel: CrossValidatorModel = cv.fit(training)
----

`CrossValidator` is a link:spark-mllib-MLWritable.md[MLWritable].

[[parameters]]
.CrossValidator' Parameters
[cols="1,1,2",options="header",width="100%"]
|===
| Parameter
| Default Value
| Description

| [[estimator]] `estimator`
| (undefined)
| link:spark-mllib-Estimator.md[Estimator] for best model selection.

| [[estimatorParamMaps]] `estimatorParamMaps`
| (undefined)
| Param maps for the <<estimator, estimator>>

| [[evaluator]] `evaluator`
| (undefined)
| link:spark-mllib-Evaluator.md[Evaluator] to select hyper-parameters that maximize the validated metric

| [[numFolds]] `numFolds`
| `3`
| The number of folds for cross validation

Must be at least `2`.

| [[parallelism]] `parallelism`
| `1`
| The number of threads to use while <<fit, fitting a model>>

Must be at least `1`.

| [[seed]] `seed`
|
| Random seed
|===

[TIP]
====
Enable `INFO` or `DEBUG` logging levels for `org.apache.spark.ml.tuning.CrossValidator` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.ml.tuning.CrossValidator=DEBUG
```

Refer to link:../spark-logging.md[Logging].
====

=== [[fit]] Finding The Best Model -- `fit` Method

[source, scala]
----
fit(dataset: Dataset[_]): CrossValidatorModel
----

NOTE: `fit` is part of link:spark-mllib-Estimator.md#fit[Estimator Contract] to fit a model (i.e. produce a model).

`fit` link:spark-mllib-PipelineStage.md#transformSchema[validates the schema] (with logging turned on).

You should see the following DEBUG message in the logs:

```
DEBUG CrossValidator: Input schema: [json]
```

`fit` makes sure that <<estimator, estimator>>, <<evaluator, evaluator>>, <<estimatorParamMaps, estimatorParamMaps>> and <<parallelism, parallelism>> parameters are defined or reports a `NoSuchElementException`.

```
java.util.NoSuchElementException: Failed to find a default value for [name]
```

`fit` link:spark-mllib-HasParallelism.md#getExecutionContext[creates] a `ExecutionContext` (per <<parallelism, parallelism>> parameter).

`fit` link:spark-mllib-Instrumentation.md#create[creates] a `Instrumentation` and requests it to link:spark-mllib-Instrumentation.md#logParams[print] out the parameters <<numFolds, numFolds>>, <<seed, seed>>, <<parallelism, parallelism>> to the logs.

```
INFO ...FIXME
```

`fit` requests `Instrumentation` to link:spark-mllib-ValidatorParams.md#logTuningParams[print out the tuning parameters to the logs].

```
INFO ...FIXME
```

`fit` link:spark-mllib-MLUtils.md#kFold[kFolds] the `RDD` of the `dataset` per <<numFolds, numFolds>> and <<seed, seed>> parameters.

NOTE: `fit` passes the underlying RDD of the `dataset` to link:spark-mllib-MLUtils.md#kFold[kFolds].

`fit` <<fit-computing-metrics, computes metrics>> for every pair of training and validation RDDs.

`fit` calculates the average metrics over all kFolds.

You should see the following INFO message in the logs:

```
INFO Average cross-validation metrics: [metrics]
```

`fit` requests the <<evaluator, Evaluator>> for the link:spark-mllib-Evaluator.md#isLargerBetter[best cross-validation metric].

You should see the following INFO message in the logs:

```
INFO Best set of parameters:
[estimatorParamMap]
INFO Best cross-validation metric: [bestMetric].
```

`fit` requests the <<estimator, Estimator>> to link:spark-mllib-Estimator.md#fit[fit the best model] (for the `dataset` and the best set of <<estimatorParamMaps, estimatorParamMap>>).

You should see the following INFO message in the logs:

```
INFO training finished
```

In the end, `fit` link:spark-mllib-CrossValidatorModel.md#creating-instance[creates] a `CrossValidatorModel` (for the <<uid, ID>>, the best model and the average metrics for every kFold) and link:spark-mllib-Params.md#copyValues[copies parameters] to it.

==== [[fit-computing-metrics]] fit and Computing Metric for Training and Validation RDDs

`fit` computes metrics for every pair of training and validation RDDs (from link:spark-mllib-MLUtils.md#kFold[kFold]).

`fit` creates and persists training and validation datasets.

TIP: You can monitor the storage for persisting the datasets in web UI's link:../spark-webui-storage.md[Storage] tab.

`fit` Prints out the following DEBUG message to the logs

```
DEBUG Train split [index] with multiple sets of parameters.
```

For every map in <<estimatorParamMaps, estimatorParamMaps>> parameter `fit` link:spark-mllib-Estimator.md#fit-paramMap[fits a model] using the <<estimator, Estimator>>.

`fit` does the fitting in parallel per <<parallelism, parallelism>> parameter.

NOTE: <<parallelism, parallelism>> parameter defaults to `1`, i.e. no parallelism for fitting models.

NOTE: `fit` unpersists the training data (per pair of training and validation RDDs) when all models have been trained.

`fit` requests the models to link:spark-mllib-Transformer.md#transform-paramMap[transform] their respective validation datasets (with the corresponding parameters from <<estimatorParamMaps, estimatorParamMaps>>) and then requests the <<evaluator, Evaluator>> to link:spark-mllib-Evaluator.md#evaluate[evaluate] the transformed datasets.

`fit` prints out the following DEBUG message to the logs:

```
DEBUG Got metric [metric] for model trained with $paramMap.
```

`fit` waits until all metrics are available and link:spark-sql-caching.md#unpersist[unpersists] the validation dataset.

=== [[creating-instance]] Creating CrossValidator Instance

`CrossValidator` takes the following when created:

* [[uid]] Unique ID

=== [[transformSchema]] Validating and Transforming Schema -- `transformSchema` Method

[source, scala]
----
transformSchema(schema: StructType): StructType
----

NOTE: `transformSchema` is part of link:spark-mllib-PipelineStage.md#transformSchema[PipelineStage Contract].

`transformSchema` simply passes the call to link:spark-mllib-ValidatorParams.md#transformSchemaImpl[transformSchemaImpl] (that is shared between `CrossValidator` and link:spark-mllib-TrainValidationSplit.md[TrainValidationSplit]).
