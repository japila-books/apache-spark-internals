== [[TaskMemoryManager]] TaskMemoryManager

`TaskMemoryManager` manages the memory allocated to an link:spark-taskscheduler-tasks.adoc[individual task].

`TaskMemoryManager` assumes that:

* The number of bits to address pages (aka `PAGE_NUMBER_BITS`) is `13`
* The number of bits to encode offsets in data pages (aka `OFFSET_BITS`) is `51` (i.e. 64 bits - `PAGE_NUMBER_BITS`)
* The number of entries in the <<pageTable, page table>> and <<allocatedPages, allocated pages>> (aka `PAGE_TABLE_SIZE`) is `8192` (i.e. 1 << `PAGE_NUMBER_BITS`)
* The maximum page size (aka `MAXIMUM_PAGE_SIZE_BYTES`) is `15GB` (i.e. `((1L << 31) - 1) * 8L`)

.`TaskMemoryManager` Internal Registries
[cols="1,2",options="header",width="100%"]
|===
| Name | Description
| [[pageTable]] `pageTable` | The array of size `PAGE_TABLE_SIZE` with indices being `MemoryBlock` objects.

When <<allocatePage, allocating a `MemoryBlock` page for Tungsten consumers>>, the index corresponds to `pageNumber` that points to the `MemoryBlock` page allocated.

| [[allocatedPages]] `allocatedPages` | Collection of flags (`true` or `false` values) of size `PAGE_TABLE_SIZE` with all bits initially disabled (i.e. `false`).

TIP: `allocatedPages` is https://docs.oracle.com/javase/8/docs/api/java/util/BitSet.html[java.util.BitSet].

When <<allocatePage, allocatePage>> is called, it will record the page in the registry by setting the bit at the specified index (that corresponds to the allocated page) to `true`.

| [[consumers]] `consumers` | Set of link:spark-MemoryConsumer.adoc[MemoryConsumers]

| [[acquiredButNotUsed]] `acquiredButNotUsed` | The size of memory allocated but not used.
|===

NOTE: `TaskMemoryManager` is used to link:spark-taskscheduler-TaskContextImpl.adoc#creating-instance[create a `TaskContextImpl`].

[TIP]
====
Enable `INFO`, `DEBUG` or even `TRACE` logging levels for `org.apache.spark.memory.TaskMemoryManager` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.memory.TaskMemoryManager=TRACE
```

Refer to link:spark-logging.adoc[Logging].
====

CAUTION: FIXME How to trigger the messages in the logs? What to execute to have them printed out to the logs?

=== [[cleanUpAllAllocatedMemory]] `cleanUpAllAllocatedMemory` Method

`cleanUpAllAllocatedMemory` clears <<pageTable, page table>>.

CAUTION: FIXME

All recorded <<consumers, consumers>> are queried for the size of used memory. If the memory used is greater than 0, the following WARN message is printed out to the logs:

```
WARN TaskMemoryManager: leak [bytes] memory from [consumer]
```

The `consumers` collection is then cleared.

link:spark-MemoryManager.adoc#releaseExecutionMemory[MemoryManager.releaseExecutionMemory] is executed to release the memory that is not used by any consumer.

Before `cleanUpAllAllocatedMemory` returns, it calls link:spark-MemoryManager.adoc#releaseAllExecutionMemoryForTask[MemoryManager.releaseAllExecutionMemoryForTask] that in turn becomes the return value.

CAUTION: FIXME Image with the interactions to `MemoryManager`.

=== [[pageSizeBytes]] `pageSizeBytes` Method

CAUTION: FIXME

=== [[releaseExecutionMemory]] `releaseExecutionMemory` Method

CAUTION: FIXME

=== [[showMemoryUsage]] `showMemoryUsage` Method

CAUTION: FIXME

=== [[creating-instance]] Creating TaskMemoryManager Instance

[source, java]
----
TaskMemoryManager(MemoryManager memoryManager, long taskAttemptId)
----

A single `TaskMemoryManager` manages the memory of a single task (by the task's `taskAttemptId`).

NOTE: Although the constructor parameter `taskAttemptId` refers to a task's attempt id it is really a `taskId`. It should be changed perhaps?

When called, the constructor uses the input link:spark-MemoryManager.adoc[MemoryManager] to know whether it is in link:spark-MemoryManager.adoc#tungstenMemoryMode[Tungsten memory mode] (disabled by default) and saves the `MemoryManager` and `taskAttemptId` for later use.

It also initializes the internal <<consumers, consumers>> to be empty.

NOTE: When a link:spark-executor-TaskRunner.adoc#run[`TaskRunner` starts running], it creates a new instance of `TaskMemoryManager` for the task by `taskId`. It then assigns the `TaskMemoryManager` to the individual task before it runs.

.Creating TaskMemoryManager for Task
image::images/spark-taskmemorymanager-creating-instance.png[align="center"]

=== [[acquireExecutionMemory]] Acquiring Execution Memory -- `acquireExecutionMemory` Method

[source, java]
----
long acquireExecutionMemory(long required, MemoryConsumer consumer)
----

`acquireExecutionMemory` allocates up to `required` size of memory for `consumer`. When no memory could be allocated, it calls `spill` on every consumer, itself including. Finally, `acquireExecutionMemory` returns the allocated memory.

NOTE: `acquireExecutionMemory` synchronizes on itself, and so no other calls on the object could be completed.

NOTE: link:spark-MemoryConsumer.adoc[MemoryConsumer] knows its mode -- on- or off-heap.

`acquireExecutionMemory` first calls `memoryManager.acquireExecutionMemory(required, taskAttemptId, mode)`.

TIP: `TaskMemoryManager` is a mere wrapper of `MemoryManager` to track <<consumers, consumers>>?

CAUTION: FIXME

When the memory obtained is less than requested (by `required`), `acquireExecutionMemory` requests all <<consumers, consumers>> to link:spark-MemoryConsumer.adoc#spill[release memory (by spilling it to disk)].

NOTE: `acquireExecutionMemory` requests memory from consumers that work in the same mode except the requesting one.

You may see the following DEBUG message when `spill` released some memory:

```
DEBUG Task [taskAttemptId] released [bytes] from [consumer] for [consumer]
```

`acquireExecutionMemory` calls `memoryManager.acquireExecutionMemory(required, taskAttemptId, mode)` again (it called it at the beginning).

It does the memory acquisition until it gets enough memory or there are no more consumers to request `spill` from.

You may also see the following ERROR message in the logs when there is an error while requesting `spill` with `OutOfMemoryError` followed.

```
ERROR error while calling spill() on [consumer]
```

If the earlier `spill` on the consumers did not work out and there is still memory to be acquired, `acquireExecutionMemory` link:spark-MemoryConsumer.adoc#spill[requests the input `consumer` to spill memory to disk] (that in fact requested more memory!)

If the `consumer` releases some memory, you should see the following DEBUG message in the logs:

```
DEBUG Task [taskAttemptId] released [bytes] from itself ([consumer])
```

`acquireExecutionMemory` calls `memoryManager.acquireExecutionMemory(required, taskAttemptId, mode)` once more.

NOTE: `memoryManager.acquireExecutionMemory(required, taskAttemptId, mode)` could have been called "three" times, i.e. at the very beginning, for each consumer, and on itself.

It records the `consumer` in <<consumers, consumers>> registry.

You should see the following DEBUG message in the logs:

```
DEBUG Task [taskAttemptId] acquired [bytes] for [consumer]
```

NOTE: `acquireExecutionMemory` is called when a link:spark-MemoryConsumer.adoc#acquireMemory[`MemoryConsumer` tries to acquires a memory] and <<allocatePage, allocatePage>>.

=== [[getPage]] Getting Page -- `getPage` Method

CAUTION: FIXME

=== [[getOffsetInPage]] Getting Page Offset -- `getOffsetInPage` Method

CAUTION: FIXME

=== [[freePage]] Freeing Memory Page -- `freePage` Method

CAUTION: FIXME

=== [[allocatePage]] Allocating Memory Block for Tungsten Consumers -- `allocatePage` Method

[source, java]
----
MemoryBlock allocatePage(long size, MemoryConsumer consumer)
----

NOTE: It only handles *Tungsten Consumers*, i.e. link:spark-MemoryConsumer.adoc[MemoryConsumers] in  `tungstenMemoryMode` mode.

`allocatePage` allocates a block of memory (aka _page_) smaller than `MAXIMUM_PAGE_SIZE_BYTES` maximum size.

It checks `size` against the internal `MAXIMUM_PAGE_SIZE_BYTES` maximum size. If it is greater than the maximum size, the following `IllegalArgumentException` is thrown:

```
Cannot allocate a page with more than [MAXIMUM_PAGE_SIZE_BYTES] bytes
```

It then <<acquireExecutionMemory, acquires execution memory>> (for the input `size` and `consumer`).

It finishes by returning `null` when no execution memory could be acquired.

With the execution memory acquired, it finds the smallest unallocated page index and records the page number (using <<allocatedPages, allocatedPages>> registry).

If the index is `PAGE_TABLE_SIZE` or higher, <<releaseExecutionMemory, releaseExecutionMemory(acquired, consumer)>> is called and then the following `IllegalStateException` is thrown:

```
Have already allocated a maximum of [PAGE_TABLE_SIZE] pages
```

It then attempts to allocate a `MemoryBlock` from `Tungsten MemoryAllocator` (calling `memoryManager.tungstenMemoryAllocator().allocate(acquired)`).

CAUTION: FIXME What is `MemoryAllocator`?

When successful, `MemoryBlock` gets assigned `pageNumber` and it gets added to the internal <<pageTable, pageTable>> registry.

You should see the following TRACE message in the logs:

```
TRACE Allocate page number [pageNumber] ([acquired] bytes)
```

The `page` is returned.

If a `OutOfMemoryError` is thrown when allocating a `MemoryBlock` page, the following WARN message is printed out to the logs:

```
WARN Failed to allocate a page ([acquired] bytes), try again.
```

And `acquiredButNotUsed` gets `acquired` memory space with the `pageNumber` cleared in <<allocatedPages, allocatedPages>> (i.e. the index for `pageNumber` gets `false`).

CAUTION: FIXME Why is the code tracking `acquiredButNotUsed`?

Another <<allocatePage, allocatePage>> attempt is recursively tried.

CAUTION: FIXME Why is there a hope for being able to allocate a page?
