== [[SparkHadoopUtil]] SparkHadoopUtil

[TIP]
====
Enable `DEBUG` logging level for `org.apache.spark.deploy.SparkHadoopUtil` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.deploy.SparkHadoopUtil=DEBUG
```

Refer to link:spark-logging.adoc[Logging].
====

=== [[get]] Creating SparkHadoopUtil Instance -- `get` Method

CAUTION: FIXME

=== [[substituteHadoopVariables]] `substituteHadoopVariables` Method

CAUTION: FIXME

=== [[transferCredentials]] `transferCredentials` Method

CAUTION: FIXME

=== [[newConfiguration]] `newConfiguration` Method

CAUTION: FIXME

=== [[conf]] `conf` Method

CAUTION: FIXME

=== [[stopCredentialUpdater]] `stopCredentialUpdater` Method

CAUTION: FIXME

=== [[runAsSparkUser]] Running Executable Block As Spark User -- `runAsSparkUser` Method

[source, scala]
----
runAsSparkUser(func: () => Unit)
----

`runAsSparkUser` runs `func` function with Hadoop's `UserGroupInformation` of the current user as a thread local variable (and distributed to child threads). It is later used for authenticating HDFS and YARN calls.

Internally, `runAsSparkUser` reads the current username (as link:spark-sparkcontext.adoc#SPARK_USER[SPARK_USER] environment variable or the short user name from Hadoop's `UserGroupInformation`).

CAUTION: FIXME How to use `SPARK_USER` to change the current user name?

You should see the current username printed out in the following DEBUG message in the logs:

```
DEBUG YarnSparkHadoopUtil: running as user: [user]
```

It then creates a remote user for the current user (using `UserGroupInformation.createRemoteUser`), <<transferCredentials, transfers credential tokens>> and runs the input `func` function as the privileged user.
