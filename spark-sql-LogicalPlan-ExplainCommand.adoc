== [[ExplainCommand]] ExplainCommand Logical Command

`ExplainCommand` is a link:spark-sql-LogicalPlan-RunnableCommand.adoc[logical command] with side effect that allows users to see how a structured query is structured and will eventually be executed, i.e. shows logical and physical plans with or without details about codegen and cost.

When <<run, executed>>, `ExplainCommand` computes a `QueryExecution` that is then used to output a single-column `DataFrame` with the following:

1. *codegen explain*, i.e. link:spark-sql-whole-stage-codegen.adoc[WholeStageCodegen] subtrees if <<codegen, codegen>> flag is enabled.

1. *extended explain*, i.e. the parsed, analyzed, optimized logical plans with the physical plan if <<extended, extended>> flag is enabled.

1. *cost explain*, i.e. link:spark-sql-QueryExecution.adoc#optimizedPlan[optimized logical plan] with stats if <<cost, cost>> flag is enabled.

1. *simple explain*, i.e. the physical plan only when no `codegen` and `extended` flags are enabled.

`ExplainCommand` is created by Dataset's link:spark-sql-Dataset.adoc#explain[explain] operator and link:spark-sql-AstBuilder.adoc#visitExplain[EXPLAIN] SQL statement (accepting `EXTENDED` and `CODEGEN` options).

[source, scala]
----
// Explain in SQL

scala> sql("EXPLAIN EXTENDED show tables").show(truncate = false)
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|plan                                                                                                                                                                                                                                           |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|== Parsed Logical Plan ==
ShowTablesCommand

== Analyzed Logical Plan ==
tableName: string, isTemporary: boolean
ShowTablesCommand

== Optimized Logical Plan ==
ShowTablesCommand

== Physical Plan ==
ExecutedCommand
   +- ShowTablesCommand|
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
----

The following EXPLAIN variants in SQL queries are not supported:

* `EXPLAIN FORMATTED`
* `EXPLAIN LOGICAL`

[source, scala]
----
scala> sql("EXPLAIN LOGICAL show tables")
org.apache.spark.sql.catalyst.parser.ParseException:
Operation not allowed: EXPLAIN LOGICAL(line 1, pos 0)

== SQL ==
EXPLAIN LOGICAL show tables
^^^
...
----

=== [[codegenString]] `codegenString` Attribute

CAUTION: FIXME

=== [[output]] `output` Attribute

CAUTION: FIXME

=== [[creating-instance]] Creating ExplainCommand Instance

`ExplainCommand` takes the following when created:

* [[logicalPlan]] link:spark-sql-LogicalPlan.adoc[LogicalPlan]
* [[extended]] `extended` flag whether to include extended details in the output when `ExplainCommand` <<run, is executed>> (disabled by default)
* [[codegen]] `codegen` flag whether to include codegen details in the output when `ExplainCommand` <<run, is executed>> (disabled by default)
* [[cost]] `cost` flag whether to include code in the output when `ExplainCommand` <<run, is executed>> (disabled by default)

`ExplainCommand` initializes <<output, output>> attribute.

NOTE: `ExplainCommand` is created when...FIXME

=== [[run]] Computing Text Representation of QueryExecution (as Single Row) -- `run` Method

[source, scala]
----
run(sparkSession: SparkSession): Seq[Row]
----

`run` computes link:spark-sql-QueryExecution.adoc[QueryExecution] and returns its text representation in a single link:spark-sql-Row.adoc[Row].

NOTE: `run` is a part of link:spark-sql-LogicalPlan-RunnableCommand.adoc#run[RunnableCommand Contract] to execute commands.

Internally, `run` creates a `IncrementalExecution` for a streaming dataset directly or requests `SessionState` to link:spark-sql-SessionState.adoc#executePlan[execute the `LogicalPlan`].

NOTE: *Streaming Dataset* is a part of Spark Structured Streaming.

`run` then requests link:spark-sql-QueryExecution.adoc[QueryExecution] to build the output text representation, i.e. <<codegenString, codegened>>, link:spark-sql-QueryExecution.adoc#toString[extended] (with logical and physical plans), link:spark-sql-QueryExecution.adoc#toStringWithStats[with stats], or link:spark-sql-QueryExecution.adoc#simpleString[simple].

In the end, `run` link:spark-sql-Row.adoc#apply[creates a `Row`] with the text representation.
