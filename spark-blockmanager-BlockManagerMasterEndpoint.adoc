== [[BlockManagerMasterEndpoint]] BlockManagerMasterEndpoint -- BlockManagerMaster RPC Endpoint

`BlockManagerMasterEndpoint` is the link:spark-rpc.adoc#ThreadSafeRpcEndpoint[ThreadSafeRpcEndpoint] for link:spark-BlockManagerMaster.adoc[BlockManagerMaster] under *BlockManagerMaster* name.

`BlockManagerMasterEndpoint` tracks status of the link:spark-blockmanager.adoc[BlockManagers] (on the executors) in a Spark application.

<<creating-instance, `BlockManagerMasterEndpoint` is created>> when link:spark-sparkenv.adoc#create[`SparkEnv` is created] (for the driver and executors).

[[messages]]
.BlockManagerMaster RPC Endpoint's Messages (in alphabetical order)
[width="100%",cols="1,2",options="header"]
|===
| Message
| When posted?

| <<RegisterBlockManager, RegisterBlockManager>>
| Posted when `BlockManagerMaster` link:spark-BlockManagerMaster.adoc#registerBlockManager[registers a `BlockManager`].

| <<UpdateBlockInfo, UpdateBlockInfo>>
| Posted when `BlockManagerMaster` link:spark-BlockManagerMaster.adoc#updateBlockInfo[receives a block status update (from BlockManager on an executor)].
|===

[[internal-registries]]
.BlockManagerMasterEndpoint's Internal Registries and Counters
[cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| [[blockManagerIdByExecutor]] `blockManagerIdByExecutor`
| FIXME

| [[blockManagerInfo]] `blockManagerInfo`
| Lookup table of `BlockManagerInfo` per link:spark-blockmanager.adoc#BlockManagerId[BlockManagerId]

Updated when `BlockManagerMasterEndpoint` <<register, registers a new `BlockManager`>> or <<removeBlockManager, removes a `BlockManager`>>

| [[blockLocations]] `blockLocations`
| Collection of ``BlockId``s and their locations (as `BlockManagerId`).

Used in `removeRdd` to remove blocks for a RDD, `removeBlockManager` to remove blocks after a BlockManager gets removed, `removeBlockFromWorkers`, `updateBlockInfo`, and <<getLocations, getLocations>>.
|===

[TIP]
====
Enable `INFO` logging level for `org.apache.spark.storage.BlockManagerMasterEndpoint` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.storage.BlockManagerMasterEndpoint=INFO
```

Refer to link:spark-logging.adoc[Logging].
====

=== [[storageStatus]] `storageStatus` Internal Method

CAUTION: FIXME

=== [[getLocationsMultipleBlockIds]] `getLocationsMultipleBlockIds` Method

CAUTION: FIXME

=== [[removeShuffle]] Removing Shuffle Blocks -- `removeShuffle` Internal Method

CAUTION: FIXME

=== [[UpdateBlockInfo]] UpdateBlockInfo

[source, scala]
----
class UpdateBlockInfo(
  var blockManagerId: BlockManagerId,
  var blockId: BlockId,
  var storageLevel: StorageLevel,
  var memSize: Long,
  var diskSize: Long)
----

When `RegisterBlockManager` arrives, `BlockManagerMasterEndpoint`...FIXME

CAUTION: FIXME

=== [[RemoveExecutor]] RemoveExecutor

[source, scala]
----
RemoveExecutor(execId: String)
----

When `RemoveExecutor` is received, <<removeExecutor, executor `execId` is removed>> and the response `true` sent back.

NOTE: `RemoveExecutor` is posted when link:spark-BlockManagerMaster.adoc#removeExecutor[`BlockManagerMaster` removes an executor].

=== [[getPeers]] Finding Peers of BlockManager -- `getPeers` Internal Method

[source, scala]
----
getPeers(blockManagerId: BlockManagerId): Seq[BlockManagerId]
----

`getPeers` finds all the registered `BlockManagers` (using <<blockManagerInfo, blockManagerInfo>> internal registry) and checks if the input `blockManagerId` is amongst them.

If the input `blockManagerId` is registered, `getPeers` returns all the registered `BlockManagers` but the one on the driver and `blockManagerId`.

Otherwise, `getPeers` returns no `BlockManagers`.

NOTE: *Peers* of a link:spark-blockmanager.adoc[BlockManager] are the other BlockManagers in a cluster (except the driver's BlockManager). Peers are used to know the available executors in a Spark application.

NOTE: `getPeers` is used exclusively when `BlockManagerMasterEndpoint` link:spark-blockmanager-BlockManagerMasterEndpoint.adoc#GetPeers[handles `GetPeers` message].

=== [[GetPeers]] Finding Peers of BlockManager -- `GetPeers` Message

[source, scala]
----
GetPeers(blockManagerId: BlockManagerId)
extends ToBlockManagerMaster
----

`GetPeers` replies with the <<getPeers, peers>> of `blockManagerId`.

NOTE: *Peers* of a link:spark-blockmanager.adoc[BlockManager] are the other BlockManagers in a cluster (except the driver's BlockManager). Peers are used to know the available executors in a Spark application.

NOTE: `GetPeers` is posted when link:spark-BlockManagerMaster.adoc#getPeers[`BlockManagerMaster` requests the peers of a `BlockManager`].

=== [[BlockManagerHeartbeat]] BlockManagerHeartbeat

CAUTION: FIXME

=== [[GetLocations]] `GetLocations` Message

[source, scala]
----
GetLocations(blockId: BlockId)
extends ToBlockManagerMaster
----

`GetLocations` replies with the <<getLocations, locations>> of `blockId`.

NOTE: `GetLocations` is posted when link:spark-BlockManagerMaster.adoc#getLocations-block[`BlockManagerMaster` requests the block locations of a single block].

=== [[GetLocationsMultipleBlockIds]] `GetLocationsMultipleBlockIds` Message

[source, scala]
----
GetLocationsMultipleBlockIds(blockIds: Array[BlockId])
extends ToBlockManagerMaster
----

`GetLocationsMultipleBlockIds` replies with the <<getLocationsMultipleBlockIds, getLocationsMultipleBlockIds>> for the input `blockIds`.

NOTE: `GetLocationsMultipleBlockIds` is posted when link:spark-BlockManagerMaster.adoc#getLocations[`BlockManagerMaster` requests the block locations for multiple blocks].

=== [[RegisterBlockManager]] RegisterBlockManager Event

[source, scala]
----
RegisterBlockManager(
  blockManagerId: BlockManagerId,
  maxMemSize: Long,
  sender: RpcEndpointRef)
----

When `RegisterBlockManager` arrives, `BlockManagerMasterEndpoint` <<register, registers the `BlockManager`>>.

==== [[register]] Registering BlockManager (on Executor) -- `register` Internal Method

[source, scala]
----
register(id: BlockManagerId, maxMemSize: Long, slaveEndpoint: RpcEndpointRef): Unit
----

`register` records the current time and registers `BlockManager` (using link:spark-blockmanager.adoc#BlockManagerId[BlockManagerId]) unless it has been registered already (in <<blockManagerInfo, blockManagerInfo>> internal registry).

NOTE: The input `maxMemSize` is the link:spark-blockmanager.adoc#maxMemory[total available on-heap and off-heap memory for storage on a `BlockManager`].

NOTE: `register` is executed when <<RegisterBlockManager, `RegisterBlockManager` has been received>>.

NOTE: Registering a `BlockManager` can only happen once for an executor (identified by `BlockManagerId.executorId` in <<blockManagerIdByExecutor, blockManagerIdByExecutor>> internal registry).

If another `BlockManager` has earlier been registered for the executor, you should see the following ERROR message in the logs:

```
ERROR Got two different block manager registrations on same executor - will replace old one [oldId] with new one [id]
```

And then <<removeExecutor, executor is removed>>.

You should see the following INFO message in the logs:

```
INFO Registering block manager [hostPort] with [bytes] RAM, [id]
```

The `BlockManager` is recorded in the internal registries:

* <<blockManagerIdByExecutor, blockManagerIdByExecutor>>
* <<blockManagerInfo, blockManagerInfo>>

CAUTION: FIXME Why does `blockManagerInfo` require a new `System.currentTimeMillis()` since `time` was already recorded?

In either case, link:spark-SparkListener.adoc#SparkListenerBlockManagerAdded[SparkListenerBlockManagerAdded] is posted (to link:spark-sparkcontext.adoc#listenerBus[listenerBus]).

NOTE: The method can only be executed on the driver where `listenerBus` is available.

CAUTION: FIXME Describe `listenerBus` + omnigraffle it.

=== Other RPC Messages

* GetLocationsMultipleBlockIds
* GetRpcHostPortForExecutor
* GetMemoryStatus
* GetStorageStatus
* GetBlockStatus
* GetMatchingBlockIds
* RemoveShuffle
* RemoveBroadcast
* RemoveBlock
* StopBlockManagerMaster
* BlockManagerHeartbeat
* HasCachedBlocks

=== [[removeExecutor]] Removing Executor -- `removeExecutor` Internal Method

[source, scala]
----
removeExecutor(execId: String)
----

`removeExecutor` prints the following INFO message to the logs:

```
INFO BlockManagerMasterEndpoint: Trying to remove executor [execId] from BlockManagerMaster.
```

If the `execId` executor is registered (in the internal <<blockManagerIdByExecutor, blockManagerIdByExecutor>> internal registry), `removeExecutor` <<removeBlockManager, removes the corresponding `BlockManager`>>.

NOTE: `removeExecutor` is executed when `BlockManagerMasterEndpoint` <<RemoveExecutor, receives a `RemoveExecutor`>> or <<register, registers a new `BlockManager`>> (and another `BlockManager` was already registered that is replaced by the new one).

=== [[removeBlockManager]] Removing BlockManager -- `removeBlockManager` Internal Method

[source, scala]
----
removeBlockManager(blockManagerId: BlockManagerId)
----

`removeBlockManager` looks up `blockManagerId` and removes the executor it was working on from the internal registries:

* <<blockManagerIdByExecutor, blockManagerIdByExecutor>>
* <<blockManagerInfo, blockManagerInfo>>

It then goes over all the blocks for the `BlockManager`, and removes the executor for each block from `blockLocations` registry.

link:spark-SparkListener.adoc#SparkListenerBlockManagerRemoved[SparkListenerBlockManagerRemoved(System.currentTimeMillis(), blockManagerId)] is posted to link:spark-sparkcontext.adoc#listenerBus[listenerBus].

You should then see the following INFO message in the logs:

```
INFO BlockManagerMasterEndpoint: Removing block manager [blockManagerId]
```

NOTE: `removeBlockManager` is used exclusively when `BlockManagerMasterEndpoint` <<removeExecutor, removes an executor>>.

=== [[getLocations]] Get Block Locations -- `getLocations` Method

[source, scala]
----
getLocations(blockId: BlockId): Seq[BlockManagerId]
----

When executed, `getLocations` looks up `blockId` in the `blockLocations` internal registry and returns the locations (as a collection of `BlockManagerId`) or an empty collection.

=== [[creating-instance]] Creating BlockManagerMasterEndpoint Instance

`BlockManagerMasterEndpoint` takes the following when created:

* [[rpcEnv]] link:spark-rpc.adoc[RpcEnv]
* [[isLocal]] Flag whether `BlockManagerMasterEndpoint` works in local or cluster mode
* [[conf]] link:spark-SparkConf.adoc[SparkConf]
* [[listenerBus]] link:spark-LiveListenerBus.adoc[LiveListenerBus]

`BlockManagerMasterEndpoint` initializes the <<internal-registries, internal registries and counters>>.
